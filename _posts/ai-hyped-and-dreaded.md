---
title: "AI; Hyped and dreaded"
date: "2023-04-16"
categories: 
  - "ai"
  - "coding"
  - "technology"
author:
  name: Ellen Schwartau
  picture: "/assets/blog/authors/ellen.png"
---

Is GPT-4 intelligent? According to [Sebastien Bubeck](https://www.linkedin.com/in/ACoAAC_2G2kB0D5D-x5k-fdgmpJAT55-R0D2uoM) the answer highly depends on your definition of intelligence. Just watched his talk where he shows if GPT-4 is intelligent according to his definition.

Especially the comparison to ChatGPTs answers blew my mind in terms of what progress there was in a relatively short amount of time, plus the ability to make the AI use tools to provide a proper solution. Still, it lacks some aspects of my definition of intelligence (Sebastien Bubeck e.g. names it's inability to plan and limitations in real time learning).

<figure>

https://www.youtube.com/watch?v=qbIk7-JPB2c

<figcaption>

Recording of Sebastien Bubecks talks about "Sparks of AI"

</figcaption>



</figure>

The evolution from ChatGPT to GPT-4 in a relatively short amount of time is stunning and makes me wonder, what more there is to come or even already existing, without the public being aware of it.

AI is either hyped or feared these days. The ones who dread it came together and wrote [an open letter to pause giant AI experiments](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) for at least 6 months, which is signed by over 26k people (16th april 2023); amongst those: Elon Musk. There were different reactions to that letter, e.g. by [Emily M. Bender](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) or the [DAIR institute](https://www.dair-institute.org/blog/letter-statement-March2023). I find it important to critically observe the usage of AI, but pausing it? In my eyes it should be more about providing transparent information about how an AI was rained, making sure that it is used in a non harmful way, and to educate end-users about what AI is and what it is not. Just last week I told a colleague, that the information provided by in that case ChatGPT is not true, just because it is provided my a machine learning algorithm. Definitely a new source for fake news, if you take those outputs at face value.

Besides hyping AI, we should also talk about introducing obligatory watermarks for AI-generated media as well as answering the question who can be held accountable for what an AI produces. How are we able to prevent the reproduction of bias and oppression based on an AIs training data and how do we make sure, that our information system is not corrupted? **What do you think?**
